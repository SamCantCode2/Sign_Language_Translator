# Sign_Language_Translator
The project involves using computer vision to create a model that can take the user's hand signals and gestures as inputs to translate them into text in sign language so as to allow for the user to be able to transcript signs to text that could be used by those who are visually impaired in the form of text to speech
